---
title: "[자료구조] 빅오 표기법 (big-O notation)"
excerpt: "빅오 표기법 (big-O notation)"

categories:
- Data Structure
tags:
- [Data Structure]

toc: true
toc_sticky: true

date: 2022-05-26
last_modified_at: 2022-05-29
---
## big-O

알고리즘의 효율성을 나타내는 지표 혹은 언어이다.



## 시간 복잡도

알고리즘을 수행하기 위해 프로세스가 수행해야하는 연산을 수치화 한 것이다.점근적 실행 시 간 (asymptotic runtime), 또 는 big-O 시간에 대한 개념 

데이터 전송 알고리즘을 예로 들어 설명하면,

- **온라인 전송** : O(s), s는 파일의 크기이다. 파일의 크기가 증가함에 따라 전송 시간 또한 선형 시간 또한 **선형적으로 증가**한다.
- **비행기를 통한 전송** : 파일 크기에 관계없이 O(1), 파일의 크기가 증가한다고 해서 전송하는 데 걸리는 시간이 늘어나지 않는다. 즉, **상수 시간**만큼 소요된다.

> 상수가 얼마나 큰지, 선형식이 얼마나 천천히 증가하는지 관계없이 숫자가 커지다 보면 **선형식은 언젠가 상수를 뛰어넘게 된다.**

![big-O](https://user-images.githubusercontent.com/57252713/170355023-63b16f32-8ab0-41ca-bc5e-8c93ef89e5a2.jpg)

### big-O, big-Ω, big-θ

- big-O : 시간의 상한
- big-Ω : 등가 개념 혹은 하한
- big-θ  : O와 Ω의 둘의 퍙균



### 최선, 최악, 평균적인 경우

**최선의 경우는 잘 사용되지 않는다**. 이유는 아무 알고리즘이나 취한 뒤 특수한 입력을 넣으면 O(1)로 동작하도록 만들 수 있기 때문이다.

대부분의 알고리즘은 최악의 경우와 평균적인 경우가 같다. 가끔 이들이 달라서 최악과 평균 모두 언급해야 되기도 한다.



## 공간 복잡도

알고리즘에는 시간뿐 아니라 메모리(혹은 공간) 또한 신경 써야 한다. 

공간 복잡도는 시간 복잡도와 평행선을 달리는 개념이다.

예를 들어, **크기가  n인 배열**을 만들고자 한다면, **O(n)**의 공간이 필요하다.  **n × n 크기의 2차원 배열**을 만들고자 한다면, **O(n^2)**의 공간이 필요하다.

재귀 호출에서 사용하는 스택 공간 또한 공간 복잡도 계산에 포함된다. 예를 들어, 다음과 같은 코드는 O(n) 시간과 O(n) 공간을 사용한다.

```cpp
int sum(int n)
{
    if (n <= 0)
    {
        return 0;
}
    return n + sum(n-1);
}
```

호출될 때마다 스택의 깊이는 깊어진다.

```
sum(4)
	-> sum(3)
		-> sum(2)
			-> sum(1)
				-> sum(0)
```

n번 호출했다고 해서 O(n) 공간을 사용한다고 말할 수 없는 경우도 있다.

예를 들어, 0과 n 사이에서 인접한 두 원소의 합을 구하는 함수는

```cpp
int pairSumSequence(int n)
{
    int sum = 0;
    for (int i = 0; i < n; ++i)
    {
        sum += pairSum(i, i + 1);
}
    return sum;
}

int pairSum(int a, int b)
{
    return a + b;
}
```

위의 코드는 pairSum 함수를 O(n)번 호출했지만, 이 함수들이 호출 스택에 동시에 존재하지는 않으므로 O(1) 공간만 사용한다.



## 상수항은 무시하라

big-O는 **단순히 증가하는 비율**을 나타내는 개념이므로, 특수한 입력에 한해 O(N) 코드가 O(1) 코드보다 빠르게 동작하는 것은 가능성이 있다.

이러한 이유로 **수행시간에서 상수항을 무시한다.** 즉, O(2N)으로 표기되어야 할 알고리즘을 실제로는 O(N)으로 표기한다.



## 지배적이지 않은 항은 무시하라

수식에서 지배적이지 않은 항은 무시해도 된다.

- O(N^2 + N)은 O(N^2)이 된다.
- O(N+logN)은 O(N)이 된다.
- O(5*2^n + 1000N^100)은 O(2^N)이 된다.

수식에 합이 남아 있는 경우도 있다. 

- O(B^2 +A)는 하나의 항으로 줄일 수 없다.  (A와 B 사이에 존재하는 관계를 알고 있지 않는 이상).



big-O 시간의 증가율을 나타내는 그래프

![bigO_graph](https://user-images.githubusercontent.com/57252713/170326442-fe0b3e23-5bde-4057-b90c-2c91d881c544.jpg)

> 출처 : https://github.com/stunstunstun/python-algorithms



## 여러 부분으로 이루어진 알고리즘 : 덧셈 vs 곱셈

- 덧셈 수행 시간 : O(A + B)

```cpp
for (int a : arrA)
{
    print(a);
}

for (int b : arrB)
{
    print(b);
}
```

알고리즘이 "A 일을 모두 끝마친 후에 B 일을 수행하라"의 형태라면 A와 B의 수행 시간을 더해야 한다. 



- 곱셈 수행 시간 : O(A × B)

```cpp
for (int a : arrA)
{
    for (int b : arrB)
    {
        print(a + "," + b);
}
}
```

알고리즘이  "A 일을 할 때마다 B 일을 수행하라"의 형태라면 A와 B의 수행 시간을 곱해야 한다.



## 상환 시간

**최악의 경우**는 가끔 발생하지만 한 번 발생하면 그 후로 꽤 오랫동안 나타나지 않으므로 비용(수행 시간)을 **분할 상환** 한다는 개념이다.

예를 들어, 동적 배열의 용량이 꽉 찼다면, 배열이 기존보다 크기가 두 배 더 큰 배열을 만든 뒤, 이전 배열의 모든 원소를 복사한다. (더블링)

이때 삽입 연산의 수행 시간은?

- (N은 배열의 크기) 배열에 N개의 원소가 들어 있을 때 새로운 원소를 삽입하려면 **O(N)**이 걸린다.
  - 크기가 2N개인 배열을 새로 만들고 기존의 모든 원소를 새 배열로 복사해야 하기 때문이다.

- 하지만 대다수의 경우에는 배열에 가용 공간이 존재하고 이때의 삽입 연산은 **O(1)**이 걸린다.

배열의 크기가 2의 승수가 되었을 때 원소를 삽입하면 용량이 두 배로 증가한다. 1 + 2 + 4 + 8 + 16  +...+ N

반대로 N에서 시작해서 1이 될 때까지 절반씩 줄어드는 수열은 X + X/2 + X/4 + X/8 + ... + 1이다. 이를 합하면 대략 2N가 된다.

따라서 N개의 원소를 삽입했을 때 필요한 시간은 O(2N)이고, 이를 분할 상환해보면 삽입 한 번에 필요한 시간은 O(1)이다.

> 예를 하나 더 들자면, 분할상환 분석은 부족한 금액 혹은 남는 금액을 전체 연산에서 서로 보충해가면서 평균 비용을 도출하는 구조를 기반으로 전체 연산의 평균 비용을 도출한다고 한다.
>
> 출처 : Eth Dev Post, <https://hcn1519.github.io/articles/2017-05/amortized_analysis>



## log N 수행 시간

**이진 탐색(binary search)**를 예를 들어 설명하자면, 이진 탐색은 N개의 **정렬된 원소가 들어 있는 배열**에서 원소 x를 찾을 때 사용된다.

먼저 원소 x와 배열의 중간값을 비교하고 **'x==중간값'**을 만족하면 이를 반환한다. **'x < 중간값'**일 때는 배열의 왼쪽 부분을 재탐색하고 **'x > 중간값'**일 경우에는 배열의 오른쪽 부분을 재탐색한다.

```
{1, 3, 5, 7, 9, 11, 15}에서 1 검색
	1과 7 비교. 1이 7보다 작다.
	7보다 작거나 같은 {1, 3, 5}에서 검색
		1과 3 비교. 1이 3보다 작다.
		3보다 작거나 같은 {1}에서 검색
			1과 1 비교. 1을 찾았다!
			결과를 반환한다.
```

처음에는 원소 N개가 들어있는 배열에서 시작한다. 한 단계가 지나면 탐색해야 할 원소의 개수가 N / 2로 줄어들고, 한 단계가 더 지나면 N / 4 개로 줄어든다. 그러다가 원소를 찾았거나 탐색해야 할 원소가 하나만 남으면 탐색을 중단한다.

총 수행 시간은 N을 절반씩 나누는 과정에서 몇 단계 만에 1이 되는지에 따라 결정된다.

즉, 2^k = N을 만족하는 K를 구할 때 **로그(log)**를 사용한다.

- 2^4 = 16  ->log2_16 = 4

  log2_N = k -> 2^k = N

문제의 원소의 개수가 **절반씩 줄어든다면** 그 문제의 수행 시간은 **O(logN)**이 될 가능성이 크다.



## 재귀적으로 수행 시간 구하기

```cpp
int f(int n)
{
    if (n <= 1)
    {
        return 1;
}
    return f(n - 1) + f(n - 1);
}
```

함수 f가 두 번 호출된 것을 보고 O(N^2)라고 생각할 수 있지만, 코드를 하나씩 읽어가면서 수행 시간을 계산해 보자.

f(4)는 f(3)을 두 번 호출한다. 또, f(3)은 f(2)를 두 번 호출하고.. f(1)까지 호출한다면?

![big-O_tree](https://user-images.githubusercontent.com/57252713/170355241-9f9454d0-6a0a-4d1c-a44b-f4c8ef2fd102.jpg)

트리의 깊이가 N이고, 각 노드(즉, 함수 호출)는 두 개의 자식 노드를 갖고 있다. 따라서 깊이가 한단계 깊어질 때마다 **이전보다 두 배** 더 많이 호출하게 된다.

같은 높이에 있는 노드의 개수를 세어 보면 아래와 같다.

| 깊이 | 노드의 개수 | 다른 표현방식                 | 또 다른 표현방식 |
| ---- | ----------- | ----------------------------- | ---------------- |
| 0    | 1           |                               | 2^0              |
| 1    | 2           | 2 * 이전 깊이 = 2             | 2^1              |
| 2    | 4           | 2 * 이전 깊이 = 2 * 2^1 = 2^2 | 2^2              |
| 3    | 8           | 2 * 이전 깊이 = 2 * 2^2 = 2^3 | 2^3              |
| 4    | 16          | 2 * 이전 깊이 = 2 * 2^3 = 2^4 | 2^4              |

따라서 전체 노드의 개수는 2^0 + 2^1 + 2^2 + ... + 2^N ( = 2^N - 1)이 된다.

다수의 호출로 이루어진 재귀 함수에서 수행 시간은 보통 **O(분기^깊이)**로 표현되곤 한다.

**분기(branch)**란 잭귀 함수가 자신을 **재호출하는 횟수**를 뜻한다.

따라서 위의 경우에 수행 시간은 O(2^N)이 된다.

이 알고리즘의 공간 복잡도는 O(N)이 된다. 전체 노드의 개수는 O(2^N)이지만, 특정 시각에 사용하는 공간의 크기는 O(N)이다. 따라서 필요한 가용 메모리의 크기는 O(N)이면 충분하다.



#### 참고

> 게일 라크만 맥도웰, 『코딩 인터뷰 완전 분석 189가지 프로그래밍 문제와 해법』, 이창현, 인사이트(2017), p60 ~ 70

